import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import joblib
import json
from pathlib import Path
from typing import Dict, List, Tuple
from collections import Counter
import warnings

class PIXMLTrainer:
    def __init__(self, min_samples_per_class=3):
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words=None)
        self.classifier = RandomForestClassifier(n_estimators=100, random_state=42)
        self.models_path = Path('data/models')
        self.models_path.mkdir(exist_ok=True)
        self.min_samples_per_class = min_samples_per_class
        
    def load_annotations(self, annotations_path: str) -> List[Dict]:
        """Carrega as anotaÃ§Ãµes do arquivo JSON"""
        with open(annotations_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data['anotacoes']
    
    def prepare_training_data(self, annotations: List[Dict]) -> Tuple[List[str], List[str]]:
        """Prepara dados de treinamento baseado nas anotaÃ§Ãµes com agrupamento inteligente"""
        texts = []
        labels = []
        
        # Primeira passagem: coletar todos os labels para anÃ¡lise
        temp_labels = []
        temp_texts = []
        
        for annotation in annotations:
            # Criar texto combinado com todas as informaÃ§Ãµes
            combined_text = f"""
            {annotation.get('valor', '')}
            {annotation.get('data', '')}
            {annotation.get('horario', '')}
            {annotation.get('destinatario', {}).get('nome', '')}
            {annotation.get('destinatario', {}).get('instituicao', '')}
            {annotation.get('remetente', {}).get('nome', '')}
            {annotation.get('remetente', {}).get('instituicao', '')}
            {annotation.get('tipo', '')}
            """.strip()
            
            # Identificar banco pela instituiÃ§Ã£o
            instituicao_remetente = annotation.get('remetente', {}).get('instituicao', '').lower()
            instituicao_destinatario = annotation.get('destinatario', {}).get('instituicao', '').lower()
            
            bank_label = self._identify_bank_from_institution(
                instituicao_remetente, instituicao_destinatario
            )
            
            temp_texts.append(combined_text)
            temp_labels.append(bank_label)
        
        # Analisar distribuiÃ§Ã£o de classes
        label_counts = Counter(temp_labels)
        print(f"ğŸ“Š DistribuiÃ§Ã£o de classes antes do agrupamento:")
        for label, count in sorted(label_counts.items()):
            print(f"   {label}: {count} exemplos")
        
        # Agrupar classes com poucos exemplos
        major_classes = {label for label, count in label_counts.items() 
                        if count >= self.min_samples_per_class}
        
        print(f"\nğŸ¯ Classes principais (>= {self.min_samples_per_class} exemplos): {sorted(major_classes)}")
        
        # Segunda passagem: aplicar agrupamento
        for text, label in zip(temp_texts, temp_labels):
            if label in major_classes:
                final_label = label
            else:
                final_label = 'outros_bancos'  # Agrupa bancos com poucos exemplos
            
            texts.append(text)
            labels.append(final_label)
        
        # Mostrar distribuiÃ§Ã£o final
        final_label_counts = Counter(labels)
        print(f"\nğŸ“Š DistribuiÃ§Ã£o final de classes:")
        for label, count in sorted(final_label_counts.items()):
            print(f"   {label}: {count} exemplos")
        
        return texts, labels
    
    def _identify_bank_from_institution(self, inst_remetente: str, inst_destinatario: str) -> str:
        """Identifica o banco baseado nas instituiÃ§Ãµes"""
        institutions = f"{inst_remetente} {inst_destinatario}".lower()
        
        # Mapeamento mais abrangente baseado nas anotaÃ§Ãµes reais
        if any(term in institutions for term in ['nubank', 'nu pagamentos']):
            return 'nubank'
        elif any(term in institutions for term in ['inter', 'banco inter']):
            return 'inter'
        elif any(term in institutions for term in ['itau', 'unibanco']):
            return 'itau'
        elif 'will' in institutions:
            return 'will'
        elif 'picpay' in institutions:
            return 'picpay'
        elif any(term in institutions for term in ['btg', 'pactual']):
            return 'btg'
        elif any(term in institutions for term in ['caixa', 'econÃ´mica']):
            return 'caixa'
        elif any(term in institutions for term in ['brasil', 'bco do brasil']):
            return 'bb'
        elif any(term in institutions for term in ['pagbank', 'pagseguro']):
            return 'pagbank'
        elif any(term in institutions for term in ['cloudwalk', 'mercado pago']):
            return 'fintech'
        else:
            return 'unknown'
    
    def train_bank_classifier(self, annotations_path: str):
        """Treina classificador para identificaÃ§Ã£o de bancos com validaÃ§Ã£o inteligente"""
        print("ğŸš€ Iniciando treinamento do classificador de bancos...")
        
        try:
            annotations = self.load_annotations(annotations_path)
            print(f"ğŸ“ Carregadas {len(annotations)} anotaÃ§Ãµes")
            
            texts, labels = self.prepare_training_data(annotations)
            
            # Verificar se hÃ¡ dados suficientes
            if len(set(labels)) < 2:
                print("âš ï¸  Aviso: Apenas uma classe encontrada. Criando modelo bÃ¡sico...")
                self._create_basic_model(texts, labels)
                return
            
            # VetorizaÃ§Ã£o
            print("ğŸ”„ Vetorizando textos...")
            X = self.vectorizer.fit_transform(texts)
            y = np.array(labels)
            
            # Verificar se podemos fazer stratify
            label_counts = Counter(labels)
            min_count = min(label_counts.values())
            
            if min_count >= 2:
                # Pode usar stratify
                print("âœ… Usando divisÃ£o estratificada")
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42, stratify=y
                )
                use_validation = True
            else:
                # NÃ£o pode usar stratify
                print("âš ï¸  Usando divisÃ£o simples (sem estratificaÃ§Ã£o)")
                warnings.filterwarnings('ignore')
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42
                )
                use_validation = len(X_test) > 0 and len(set(y_test)) > 1
            
            # Treinamento
            print("ğŸ§  Treinando modelo...")
            self.classifier.fit(X_train, y_train)
            
            # AvaliaÃ§Ã£o (se possÃ­vel)
            if use_validation and len(X_test) > 0:
                y_pred = self.classifier.predict(X_test)
                print("\nğŸ“Š RelatÃ³rio de ClassificaÃ§Ã£o:")
                print(classification_report(y_test, y_pred, zero_division=0))
                
                # Calcular acurÃ¡cia
                accuracy = np.mean(y_pred == y_test)
                print(f"ğŸ¯ AcurÃ¡cia: {accuracy:.2%}")
            else:
                print("â„¹ï¸  ValidaÃ§Ã£o nÃ£o disponÃ­vel (dados insuficientes)")
            
            # Salvar modelos
            print("ğŸ’¾ Salvando modelos...")
            joblib.dump(self.vectorizer, self.models_path / 'vectorizer.pkl')
            joblib.dump(self.classifier, self.models_path / 'bank_classifier.pkl')
            
            # Salvar metadados
            metadata = {
                'classes': list(set(labels)),
                'total_samples': len(texts),
                'class_distribution': dict(Counter(labels)),
                'min_samples_per_class': self.min_samples_per_class
            }
            
            with open(self.models_path / 'model_metadata.json', 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… Modelos salvos em: {self.models_path}")
            print(f"ğŸ“‹ Classes treinadas: {sorted(set(labels))}")
            
        except Exception as e:
            print(f"âŒ Erro durante o treinamento: {e}")
            # Criar modelo bÃ¡sico em caso de erro
            self._create_basic_model(['texto_exemplo'], ['nubank'])
    
    def _create_basic_model(self, texts: List[str], labels: List[str]):
        """Cria um modelo bÃ¡sico quando hÃ¡ problemas com os dados"""
        print("ğŸ”§ Criando modelo bÃ¡sico...")
        
        # Adicionar exemplos sintÃ©ticos para ter pelo menos 2 classes
        synthetic_texts = [
            "nubank nu pagamentos transferÃªncia",
            "inter banco inter pix",
            "itau unibanco transferÃªncia",
            "outros banco transferÃªncia"
        ]
        synthetic_labels = ['nubank', 'inter', 'itau', 'outros_bancos']
        
        all_texts = texts + synthetic_texts
        all_labels = labels + synthetic_labels
        
        # Vetorizar e treinar
        X = self.vectorizer.fit_transform(all_texts)
        self.classifier.fit(X, all_labels)
        
        # Salvar
        joblib.dump(self.vectorizer, self.models_path / 'vectorizer.pkl')
        joblib.dump(self.classifier, self.models_path / 'bank_classifier.pkl')
        
        print("âœ… Modelo bÃ¡sico criado com dados sintÃ©ticos")
    
    def load_models(self):
        """Carrega modelos treinados"""
        try:
            self.vectorizer = joblib.load(self.models_path / 'vectorizer.pkl')
            self.classifier = joblib.load(self.models_path / 'bank_classifier.pkl')
            return True
        except FileNotFoundError:
            return False
    
    def predict_bank(self, text: str) -> str:
        """Prediz o banco baseado no texto"""
        try:
            if not hasattr(self.vectorizer, 'vocabulary_'):
                if not self.load_models():
                    return 'unknown'
            
            X = self.vectorizer.transform([text])
            prediction = self.classifier.predict(X)[0]
            
            # Se predisse 'outros_bancos', tentar identificaÃ§Ã£o manual
            if prediction == 'outros_bancos':
                manual_prediction = self._manual_bank_identification(text)
                return manual_prediction if manual_prediction != 'unknown' else prediction
            
            return prediction
            
        except Exception as e:
            print(f"âš ï¸  Erro na prediÃ§Ã£o: {e}")
            return self._manual_bank_identification(text)
    
    def _manual_bank_identification(self, text: str) -> str:
        """IdentificaÃ§Ã£o manual baseada em palavras-chave como fallback"""
        text_lower = text.lower()
        
        # PadrÃµes especÃ­ficos baseados nas anotaÃ§Ãµes
        patterns = {
            'nubank': ['nubank', 'nu pagamentos'],
            'inter': ['inter', 'banco inter'],
            'itau': ['itau', 'unibanco'],
            'will': ['will bank', 'will'],
            'picpay': ['picpay'],
            'btg': ['btg', 'pactual'],
            'caixa': ['caixa', 'econÃ´mica federal'],
            'bb': ['brasil', 'bco do brasil'],
            'pagbank': ['pagbank', 'pagseguro'],
            'c6': ['c6 bank', 'banco c6']
        }
        
        for bank, keywords in patterns.items():
            if any(keyword in text_lower for keyword in keywords):
                return bank
        
        return 'unknown'
    
    def get_model_info(self) -> Dict:
        """Retorna informaÃ§Ãµes sobre o modelo treinado"""
        try:
            metadata_path = self.models_path / 'model_metadata.json'
            if metadata_path.exists():
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                return {'status': 'Modelo nÃ£o encontrado'}
        except Exception as e:
            return {'status': f'Erro: {e}'}
